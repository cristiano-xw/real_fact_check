
# Multi-Hop Fact-Checking & Reasoning Dataset

This repository contains a specialized dataset designed for **multi-hop fact-checking**, **temporal reasoning**, and **hallucination detection**. The data is organized into two primary components: raw real-world claims scraped from fact-checking authorities, and a synthetic multi-hop dataset featuring diverse negative sampling strategies.

## ðŸ“‚ Data Files

### 1. `raw_data_example.jsonl`
**Description:** Contains raw fact-checking data collected from professional verification websites (e.g., Snopes, PolitiFact). This file serves as the ground truth source for real-world events and evidences.

**Field Definitions:**

| Field | Type | Description |
| :--- | :--- | :--- |
| `claim` | `str` | The statement or claim being verified. |
| `label` | `str` | The verdict (e.g., "False", "True", "Miscaptioned"). |
| `evidence` | `str` | The full text content/report from the fact-checking article. |
| `publishdate` | `str` | The publication date of the fact-check (YYYY-MM-DD). |
| `source` | `str` | Citations, URLs, and metadata regarding the source of the claim. |
| `tag` | `list` | Keywords or entities associated with the claim (e.g., ["India", "Turkey"]). |
| `time_sensitive` | `int` | Binary flag (`1` or `0`) indicating if temporal context is crucial for verification. |

**Example:**
```json
{
  "claim": "A video authentically shows thousands of people protesting...",
  "label": "False",
  "publishdate": "2025-03-21",
  "tag": ["India", "Turkey", "Pope Francis"],
  "evidence": "In March 2025, online users shared a rumor claiming a video showed..."
}

```

---

### 2. `multi-hop samples.jsonl`

**Description:** A synthetic dataset designed for complex reasoning tasks. Each entry contains a **True Claim** paired with multiple **Negative Samples** (Hard Negatives). These negative samples are generated by perturbing specific aspects of the true claim to test a model's ability to detect fine-grained errors.

**Top-Level Structure:**

| Field | Description |
| --- | --- |
| `hop_count` | The number of reasoning steps (hops) required to verify the claim. |
| `source_entities` | List of main entities involved in the claim. |
| `true_claim` | The positive (factually correct) sample object. |
| `negative_samples` | A list of objects, each representing a distinct type of falsehood. |

#### A. The `true_claim` Object

Represents the correct multi-hop reasoning chain.

* **`claim`**: The true statement.
* **`main_evidence`**: List of atomic evidence snippets with dates supporting the claim.
* **`sub_claims`**: A step-by-step decomposition (QA pairs) verifying the logic.
* *Format:* `{"step": 1, "question": "...", "answer": "Yes", "evidence": "..."}`



#### B. The `negative_samples` Object (Perturbation Strategies)

Each negative sample includes a `strategy` field describing how the truth was corrupted. This is crucial for evaluating fine-grained hallucination types.

| Strategy Name | Description |
| --- | --- |
| **Entity Hallucination** | Swaps a correct entity (e.g., "Weather Prediction Center") with an incorrect one (e.g., "National Hurricane Center"). |
| **Chronological Distortion** | Alters dates or sequences to break temporal logic (e.g., placing an effect before its cause). |
| **Relational Corruption** | Modifies relationships or locations (e.g., changing "Central Texas" to "West Texas"). |
| **Contextual Contradiction** | Changes the qualitative details or severity (e.g., "Moderate risk" becomes "Marginal risk"). |
| **Data Perturbation** | Modifies numerical values or categorical levels (e.g., upgrading "Moderate risk" to "High risk"). |
| **Sentiment Inversion** | Flips the outcome entirely (e.g., claiming "No risk" when there was significant risk). |

**Example:**

```json
{
  "hop_count": 3,
  "true_claim": {
    "claim": "After flooding on July 4... the WPC declared a moderate risk on July 12.",
    "label": "True"
  },
  "negative_samples": [
    {
      "strategy": "Entity Hallucination",
      "claim": "After flooding on July 4... the National Hurricane Center declared a moderate risk...",
      "label": "False",
      "explanation": "This claim hallucinates the wrong issuing entity..."
    },
    {
      "strategy": "Chronological Distortion",
      "claim": "...declared a moderate risk on July 3 (before the flood)...",
      "label": "False"
    }
  ]
}

```

